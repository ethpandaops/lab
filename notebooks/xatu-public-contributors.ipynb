{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xatu Public Contributors Analysis\n",
    "\n",
    "This notebook fetches and analyzes public contributor data from Clickhouse and generates JSON files for the frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 10:05:07,632 - xatu-public-contributors - INFO - Good to go!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from lib import Lab\n",
    "\n",
    "# Initialize lab\n",
    "lab = Lab('xatu-public-contributors', '../config.yaml')\n",
    "lab.setup()\n",
    "lab.setup_pandaops_clickhouse()\n",
    "log = lab.log\n",
    "\n",
    "# Get notebook specific config\n",
    "notebook_config = lab.get_notebook_config()\n",
    "\n",
    "writer = lab.get_data_writer()\n",
    "\n",
    "pandaops_clickhouse_client = lab.get_pandaops_clickhouse_client()\n",
    "\n",
    "log.info(\"Good to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XatuPublicContributors(time_windows=[TimeWindow(file='last_90_days', step='3d', label='Last 90d', range='-90d'), TimeWindow(file='last_30_days', step='1d', label='Last 30d', range='-30d'), TimeWindow(file='last_1_day', step='1h', label='Last 1d', range='-1d'), TimeWindow(file='last_6h', step='5m', label='Last 6h', range='-6h')], data_dir='../data/xatu-public-contributors', networks=['mainnet', 'sepolia', 'holesky'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xatu_public_contributors_config = lab.get_notebook_config().as_xatu_public_contributors()\n",
    "xatu_public_contributors_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 10:05:07,650 - xatu-public-contributors - INFO - Fetching data for last 1h\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "query = text(\"\"\"\n",
    "    SELECT\n",
    "        meta_network_name,\n",
    "        meta_client_geo_country as country,\n",
    "        meta_client_geo_continent_code as continent,\n",
    "        meta_client_geo_city as city,\n",
    "        meta_client_name,\n",
    "        meta_consensus_implementation,\n",
    "        count(*) as count\n",
    "    FROM beacon_api_eth_v1_events_block FINAL\n",
    "    WHERE\n",
    "        slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "        AND meta_network_name IN (:networks)\n",
    "        AND meta_client_name != ''\n",
    "        AND meta_client_name IS NOT NULL\n",
    "    GROUP BY meta_network_name, country, continent, city, meta_client_name, meta_consensus_implementation\n",
    "\"\"\")\n",
    "\n",
    "# Get last 1h window\n",
    "end_date = datetime.now(timezone.utc)\n",
    "start_date = end_date - timedelta(hours=1)\n",
    "\n",
    "# Format dates without microseconds for Clickhouse\n",
    "start_str = start_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "end_str = end_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "log.info(\"Fetching data for last 1h\")\n",
    "\n",
    "result = pandaops_clickhouse_client.execute(\n",
    "    query,\n",
    "    {\n",
    "        \"start_date\": start_str,\n",
    "        \"end_date\": end_str,\n",
    "        \"networks\": xatu_public_contributors_config.networks\n",
    "    }\n",
    ")\n",
    "rows = result.fetchall()\n",
    "\n",
    "if len(rows) == 0:\n",
    "    log.warning(\"No data found for last 24h\")\n",
    "else:\n",
    "    # Build summary data per network\n",
    "    summary = {\n",
    "        \"updated_at\": int(datetime.now(timezone.utc).timestamp()),\n",
    "        \"networks\": {}\n",
    "    }\n",
    "    \n",
    "    for network in xatu_public_contributors_config.networks:\n",
    "        summary[\"networks\"][network] = {\n",
    "            \"total_nodes\": 0,\n",
    "            \"total_public_nodes\": 0,\n",
    "            \"countries\": {},\n",
    "            \"continents\": {},\n",
    "            \"cities\": {},\n",
    "            \"consensus_implementations\": {}\n",
    "        }\n",
    "\n",
    "    for row in rows:\n",
    "        network, country, continent, city, client_name, consensus_impl, count = row\n",
    "        is_public = not client_name.startswith('ethpandaops')\n",
    "        \n",
    "        # Add to network totals\n",
    "        summary[\"networks\"][network][\"total_nodes\"] += 1\n",
    "        if is_public:\n",
    "            summary[\"networks\"][network][\"total_public_nodes\"] += 1\n",
    "\n",
    "        # Add to network countries\n",
    "        if country not in summary[\"networks\"][network][\"countries\"]:\n",
    "            summary[\"networks\"][network][\"countries\"][country] = {\"total_nodes\": 0, \"public_nodes\": 0}\n",
    "        summary[\"networks\"][network][\"countries\"][country][\"total_nodes\"] += 1\n",
    "        if is_public:\n",
    "            summary[\"networks\"][network][\"countries\"][country][\"public_nodes\"] += 1\n",
    "\n",
    "        # Add to network continents\n",
    "        if continent not in summary[\"networks\"][network][\"continents\"]:\n",
    "            summary[\"networks\"][network][\"continents\"][continent] = {\"total_nodes\": 0, \"public_nodes\": 0}\n",
    "        summary[\"networks\"][network][\"continents\"][continent][\"total_nodes\"] += 1\n",
    "        if is_public:\n",
    "            summary[\"networks\"][network][\"continents\"][continent][\"public_nodes\"] += 1\n",
    "\n",
    "        # Add to network cities\n",
    "        if city not in summary[\"networks\"][network][\"cities\"]:\n",
    "            summary[\"networks\"][network][\"cities\"][city] = {\"total_nodes\": 0, \"public_nodes\": 0}\n",
    "        summary[\"networks\"][network][\"cities\"][city][\"total_nodes\"] += 1\n",
    "        if is_public:\n",
    "            summary[\"networks\"][network][\"cities\"][city][\"public_nodes\"] += 1\n",
    "\n",
    "        # Add to network consensus implementations\n",
    "        if consensus_impl not in summary[\"networks\"][network][\"consensus_implementations\"]:\n",
    "            summary[\"networks\"][network][\"consensus_implementations\"][consensus_impl] = {\n",
    "                \"total_nodes\": 0, \n",
    "                \"public_nodes\": 0\n",
    "            }\n",
    "        summary[\"networks\"][network][\"consensus_implementations\"][consensus_impl][\"total_nodes\"] += 1\n",
    "        if is_public:\n",
    "            summary[\"networks\"][network][\"consensus_implementations\"][consensus_impl][\"public_nodes\"] += 1\n",
    "\n",
    "    # Write summary to file\n",
    "    lab.write_json(\"summary.json\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 10:05:08,041 - xatu-public-contributors - INFO - Fetching data for last_90_days, total timesteps: 30.0\n",
      "2025-01-10 10:05:08,838 - xatu-public-contributors - INFO - Found 385 countries for time window last_90_days\n",
      "2025-01-10 10:05:08,842 - xatu-public-contributors - INFO - Fetching data for last_30_days, total timesteps: 30.0\n",
      "2025-01-10 10:05:09,370 - xatu-public-contributors - INFO - Found 483 countries for time window last_30_days\n",
      "2025-01-10 10:05:09,374 - xatu-public-contributors - INFO - Fetching data for last_1_day, total timesteps: 24.0\n",
      "2025-01-10 10:05:09,781 - xatu-public-contributors - INFO - Found 400 countries for time window last_1_day\n",
      "2025-01-10 10:05:09,801 - xatu-public-contributors - INFO - Fetching data for last_6h, total timesteps: 72.0\n",
      "2025-01-10 10:05:10,253 - xatu-public-contributors - INFO - Found 1151 countries for time window last_6h\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "query = text(\"\"\"\n",
    "    WITH time_slots AS (\n",
    "        SELECT \n",
    "            toStartOfInterval(slot_start_date_time, INTERVAL :step_seconds second) as time_slot,\n",
    "            meta_client_geo_country as country,\n",
    "            meta_network_name,\n",
    "            count(distinct meta_client_name) AS total\n",
    "        FROM beacon_api_eth_v1_events_block FINAL\n",
    "        WHERE\n",
    "            slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "            AND meta_client_name NOT LIKE 'ethpandaops%'\n",
    "            AND meta_network_name IN (:networks)\n",
    "            AND meta_client_name != ''\n",
    "            AND meta_client_name IS NOT NULL\n",
    "        GROUP BY time_slot, country, meta_network_name\n",
    "    )\n",
    "    SELECT\n",
    "        time_slot as time,\n",
    "        country,\n",
    "        meta_network_name,\n",
    "        total\n",
    "    FROM time_slots\n",
    "\"\"\")\n",
    "\n",
    "countries_by_window = {}\n",
    "\n",
    "for window in xatu_public_contributors_config.time_windows:\n",
    "    start_date, end_date = window.get_time_range(datetime.now(timezone.utc))\n",
    "    step_seconds = window.get_step_seconds()\n",
    "    \n",
    "    # Format dates without microseconds for Clickhouse\n",
    "    start_str = start_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_str = end_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    total_timesteps = (end_date - start_date).total_seconds() / step_seconds\n",
    "\n",
    "    log.info(f\"Fetching data for {window.file}, total timesteps: {total_timesteps}\")\n",
    "    \n",
    "    result = pandaops_clickhouse_client.execute(\n",
    "        query,\n",
    "        {\n",
    "            \"start_date\": start_str, \n",
    "            \"end_date\": end_str,\n",
    "            \"networks\": xatu_public_contributors_config.networks,\n",
    "            \"step_seconds\": step_seconds\n",
    "        }\n",
    "    )\n",
    "    countries = result.fetchall()\n",
    "\n",
    "    if len(countries) == 0:\n",
    "        log.warning(f\"No countries found for time window {window.file}\")\n",
    "        continue\n",
    "\n",
    "    countries_by_window[window.file] = countries\n",
    "    log.info(f\"Found {len(countries)} countries for time window {window.file}\")\n",
    "    \n",
    "    # Group by network and write separate files\n",
    "    for network in xatu_public_contributors_config.networks:\n",
    "        network_countries = [c for c in countries if c[2] == network]\n",
    "        if not network_countries:\n",
    "            continue\n",
    "        \n",
    "        # Group by timestamp\n",
    "        time_grouped = []\n",
    "        for c in network_countries:\n",
    "            # Handle both date and datetime from query\n",
    "            if isinstance(c[0], datetime):\n",
    "                timestamp = int(c[0].timestamp())\n",
    "            else:\n",
    "                timestamp = int(datetime.combine(c[0], datetime.min.time()).timestamp())\n",
    "                \n",
    "            time_grouped.append({\n",
    "                \"time\": timestamp,\n",
    "                \"countries\": [{\n",
    "                    \"name\": c[1],\n",
    "                    \"value\": c[3]\n",
    "                }]\n",
    "            })\n",
    "            \n",
    "        # Merge entries with same timestamp\n",
    "        merged = {}\n",
    "        for entry in time_grouped:\n",
    "            if entry[\"time\"] not in merged:\n",
    "                merged[entry[\"time\"]] = entry\n",
    "            else:\n",
    "                merged[entry[\"time\"]][\"countries\"].extend(entry[\"countries\"])\n",
    "                \n",
    "        # Convert to list and write to file\n",
    "        final_data = list(merged.values())\n",
    "        \n",
    "        # Write to single file per time window and network\n",
    "        lab.write_json(f\"countries/{network}/{window.file}.json\", final_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 10:05:10,271 - xatu-public-contributors - INFO - Fetching data for last_90_days, total timesteps: 30.0\n",
      "2025-01-10 10:05:10,978 - xatu-public-contributors - INFO - Found 446 user entries for time window last_90_days\n",
      "2025-01-10 10:05:10,982 - xatu-public-contributors - INFO - Fetching data for last_30_days, total timesteps: 30.0\n",
      "2025-01-10 10:05:11,623 - xatu-public-contributors - INFO - Found 577 user entries for time window last_30_days\n",
      "2025-01-10 10:05:11,628 - xatu-public-contributors - INFO - Fetching data for last_1_day, total timesteps: 24.0\n",
      "2025-01-10 10:05:12,075 - xatu-public-contributors - INFO - Found 475 user entries for time window last_1_day\n",
      "2025-01-10 10:05:12,079 - xatu-public-contributors - INFO - Fetching data for last_6h, total timesteps: 72.0\n",
      "2025-01-10 10:05:12,599 - xatu-public-contributors - INFO - Found 1367 user entries for time window last_6h\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "query = text(\"\"\"\n",
    "    WITH time_slots AS (\n",
    "        SELECT \n",
    "            toStartOfInterval(slot_start_date_time, INTERVAL :step_seconds second) as time_slot,\n",
    "            extractAll(meta_client_name, '/([^/]+)/[^/]+$')[1] as username,\n",
    "            meta_network_name,\n",
    "            count(distinct meta_client_name) AS node_count\n",
    "        FROM beacon_api_eth_v1_events_block FINAL\n",
    "        WHERE\n",
    "            slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "            AND meta_client_name NOT LIKE 'ethpandaops%'\n",
    "            AND meta_network_name IN (:networks)\n",
    "            AND meta_client_name != ''\n",
    "            AND meta_client_name IS NOT NULL\n",
    "        GROUP BY time_slot, username, meta_network_name\n",
    "    )\n",
    "    SELECT\n",
    "        time_slot as time,\n",
    "        username,\n",
    "        meta_network_name,\n",
    "        node_count\n",
    "    FROM time_slots\n",
    "\"\"\")\n",
    "\n",
    "users_by_window = {}\n",
    "\n",
    "for window in xatu_public_contributors_config.time_windows:\n",
    "    start_date, end_date = window.get_time_range(datetime.now(timezone.utc))\n",
    "    step_seconds = window.get_step_seconds()\n",
    "    \n",
    "    start_str = start_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_str = end_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    total_timesteps = (end_date - start_date).total_seconds() / step_seconds\n",
    "\n",
    "    log.info(f\"Fetching data for {window.file}, total timesteps: {total_timesteps}\")\n",
    "    \n",
    "    result = pandaops_clickhouse_client.execute(\n",
    "        query,\n",
    "        {\n",
    "            \"start_date\": start_str,\n",
    "            \"end_date\": end_str,\n",
    "            \"networks\": xatu_public_contributors_config.networks,\n",
    "            \"step_seconds\": step_seconds\n",
    "        }\n",
    "    )\n",
    "    users = result.fetchall()\n",
    "\n",
    "    if len(users) == 0:\n",
    "        log.warning(f\"No users found for time window {window.file}\")\n",
    "        continue\n",
    "\n",
    "    users_by_window[window.file] = users\n",
    "    log.info(f\"Found {len(users)} user entries for time window {window.file}\")\n",
    "    \n",
    "    # Group by network and write separate files\n",
    "    for network in xatu_public_contributors_config.networks:\n",
    "        network_users = [u for u in users if u[2] == network]\n",
    "        if not network_users:\n",
    "            continue\n",
    "        \n",
    "        # Group by timestamp\n",
    "        time_grouped = []\n",
    "        for u in network_users:\n",
    "            # Handle datetime directly from query since we changed time_slot to not convert to date\n",
    "            timestamp = int(u[0].timestamp())\n",
    "            time_grouped.append({\n",
    "                \"time\": timestamp,\n",
    "                \"users\": [{\n",
    "                    \"name\": u[1],\n",
    "                    \"nodes\": u[3]\n",
    "                }]\n",
    "            })\n",
    "            \n",
    "        # Merge entries with same timestamp\n",
    "        merged = {}\n",
    "        for entry in time_grouped:\n",
    "            if entry[\"time\"] not in merged:\n",
    "                merged[entry[\"time\"]] = entry\n",
    "            else:\n",
    "                merged[entry[\"time\"]][\"users\"].extend(entry[\"users\"])\n",
    "                \n",
    "        # Convert to list and write to file\n",
    "        final_data = list(merged.values())\n",
    "        \n",
    "        # Write to single file per time window and network\n",
    "        lab.write_json(f\"users/{network}/{window.file}.json\", final_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 10:29:49,558 - xatu-public-contributors - INFO - Fetching user summary data for last 24h\n"
     ]
    },
    {
     "ename": "DatabaseException",
     "evalue": "Orig exception: Code: 47. DB::Exception: Missing columns: 'meta_client_geo_continent' while processing query: 'SELECT meta_client_name, meta_network_name, meta_consensus_implementation, meta_consensus_version, meta_client_geo_country, meta_client_geo_city, meta_client_geo_continent, slot, slot_start_date_time, row_number() OVER (PARTITION BY meta_client_name ORDER BY slot_start_date_time DESC) AS rn FROM beacon_api_eth_v1_events_block FINAL WHERE (slot_start_date_time >= (now() - toIntervalHour(24))) AND (meta_network_name IN ['mainnet', 'sepolia', 'holesky']) AND (meta_client_name != '') AND (meta_client_name IS NOT NULL)', required columns: 'meta_client_name' 'meta_client_geo_continent' 'meta_network_name' 'meta_consensus_version' 'meta_client_geo_country' 'meta_consensus_implementation' 'meta_client_geo_city' 'slot' 'slot_start_date_time', maybe you meant: 'meta_client_name', 'meta_client_geo_continent_code', 'meta_network_name', 'meta_consensus_version', 'meta_client_geo_country', 'meta_consensus_implementation', 'meta_client_geo_city', 'slot' or 'slot_start_date_time'. (UNKNOWN_IDENTIFIER) (version 24.2.3.70 (official build))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 53\u001b[0m\n\u001b[1;32m     49\u001b[0m end_str \u001b[38;5;241m=\u001b[39m end_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m lab\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching user summary data for last 24h\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m result \u001b[38;5;241m=\u001b[39m pandaops_clickhouse_client\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m     54\u001b[0m     query,\n\u001b[1;32m     55\u001b[0m     {\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetworks\u001b[39m\u001b[38;5;124m\"\u001b[39m: xatu_public_contributors_config\u001b[38;5;241m.\u001b[39mnetworks\n\u001b[1;32m     57\u001b[0m     }\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     59\u001b[0m users \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(users) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1630\u001b[0m )\n\u001b[1;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1639\u001b[0m )\n\u001b[0;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1655\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m         ret,\n\u001b[1;32m   1660\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2356\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2354\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2355\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2356\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2358\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1974\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1979\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/base.py:488\u001b[0m, in \u001b[0;36mClickHouseDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 488\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/connector.py:133\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, operation, parameters, context)\u001b[0m\n\u001b[1;32m    130\u001b[0m raw_sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare(raw_sql, context)\n\u001b[1;32m    131\u001b[0m response_gen \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mexecute(raw_sql, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end_query()\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/connector.py:232\u001b[0m, in \u001b[0;36mCursor._process_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, response):\n\u001b[1;32m    230\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(response)\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(response, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response \u001b[38;5;241m=\u001b[39m response\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/transport.py:133\u001b[0m, in \u001b[0;36mRequestsTransport.execute\u001b[0;34m(self, query, params)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    Query is returning rows and these rows should be parsed or\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    there is nothing to return.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     lines \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39miter_lines()\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/transport.py:179\u001b[0m, in \u001b[0;36mRequestsTransport._send\u001b[0;34m(self, data, params, stream)\u001b[0m\n\u001b[1;32m    177\u001b[0m     orig \u001b[38;5;241m=\u001b[39m HTTPException(r\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    178\u001b[0m     orig\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus_code\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatabaseException(orig)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mDatabaseException\u001b[0m: Orig exception: Code: 47. DB::Exception: Missing columns: 'meta_client_geo_continent' while processing query: 'SELECT meta_client_name, meta_network_name, meta_consensus_implementation, meta_consensus_version, meta_client_geo_country, meta_client_geo_city, meta_client_geo_continent, slot, slot_start_date_time, row_number() OVER (PARTITION BY meta_client_name ORDER BY slot_start_date_time DESC) AS rn FROM beacon_api_eth_v1_events_block FINAL WHERE (slot_start_date_time >= (now() - toIntervalHour(24))) AND (meta_network_name IN ['mainnet', 'sepolia', 'holesky']) AND (meta_client_name != '') AND (meta_client_name IS NOT NULL)', required columns: 'meta_client_name' 'meta_client_geo_continent' 'meta_network_name' 'meta_consensus_version' 'meta_client_geo_country' 'meta_consensus_implementation' 'meta_client_geo_city' 'slot' 'slot_start_date_time', maybe you meant: 'meta_client_name', 'meta_client_geo_continent_code', 'meta_network_name', 'meta_consensus_version', 'meta_client_geo_country', 'meta_consensus_implementation', 'meta_client_geo_city', 'slot' or 'slot_start_date_time'. (UNKNOWN_IDENTIFIER) (version 24.2.3.70 (official build))\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "lab.delete_directory(\"user-summaries\")\n",
    "\n",
    "# Query to get user activity summary for last 24h, taking latest row per node\n",
    "query = text(\"\"\"\n",
    "    WITH latest_events AS (\n",
    "        SELECT\n",
    "            meta_client_name,\n",
    "            meta_network_name,\n",
    "            meta_consensus_implementation,\n",
    "            meta_consensus_version,\n",
    "            meta_client_geo_country,\n",
    "            meta_client_geo_city,\n",
    "            meta_client_geo_continent_code,\n",
    "            slot,\n",
    "            slot_start_date_time,\n",
    "            ROW_NUMBER() OVER (PARTITION BY meta_client_name ORDER BY slot_start_date_time DESC) as rn\n",
    "        FROM beacon_api_eth_v1_events_block FINAL\n",
    "        WHERE\n",
    "            slot_start_date_time >= now() - INTERVAL 24 HOUR\n",
    "            AND meta_network_name IN (:networks)\n",
    "            AND meta_client_name != ''\n",
    "            AND meta_client_name IS NOT NULL\n",
    "    )\n",
    "    SELECT\n",
    "        CASE\n",
    "            WHEN meta_client_name LIKE 'pub%' THEN extractAll(meta_client_name, '/([^/]+)/[^/]+$')[1]\n",
    "            WHEN meta_client_name LIKE 'ethpandaops%' THEN 'ethpandaops'\n",
    "            ELSE extractAll(meta_client_name, '/([^/]+)/[^/]+/')[1]\n",
    "        END as username,\n",
    "        meta_network_name,\n",
    "        meta_client_name,\n",
    "        meta_consensus_implementation as consensus_client,\n",
    "        meta_consensus_version as consensus_version,\n",
    "        meta_client_geo_country as country,\n",
    "        meta_client_geo_city as city,\n",
    "        meta_client_geo_continent_code as continent,\n",
    "        slot as latest_slot,\n",
    "        toUnixTimestamp(slot_start_date_time) as latest_slot_start_date_time\n",
    "    FROM latest_events\n",
    "    WHERE rn = 1\n",
    "\"\"\")\n",
    "\n",
    "end_date = datetime.now(timezone.utc)\n",
    "start_date = end_date - timedelta(days=1)\n",
    "start_str = start_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "end_str = end_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "lab.log.info(f\"Fetching user summary data for last 24h\")\n",
    "\n",
    "result = pandaops_clickhouse_client.execute(\n",
    "    query,\n",
    "    {\n",
    "        \"networks\": xatu_public_contributors_config.networks\n",
    "    }\n",
    ")\n",
    "users = result.fetchall()\n",
    "\n",
    "if len(users) == 0:\n",
    "    log.warning(\"No users found in last 24h\")\n",
    "else:\n",
    "    # Group by username\n",
    "    users_by_name = {}\n",
    "    summary = []\n",
    "    for user in users:\n",
    "        username = user[0]\n",
    "        if username not in users_by_name:\n",
    "            users_by_name[username] = {\n",
    "                \"name\": username,\n",
    "                \"nodes\": []\n",
    "            }\n",
    "        \n",
    "        users_by_name[username][\"nodes\"].append({\n",
    "            \"network\": user[1],\n",
    "            \"client_name\": user[2], \n",
    "            \"consensus_client\": user[3],\n",
    "            \"consensus_version\": user[4],\n",
    "            \"country\": user[5],\n",
    "            \"city\": user[6],\n",
    "            \"continent\": user[7],\n",
    "            \"latest_slot\": user[8],\n",
    "            \"latest_slot_start_date_time\": user[9]\n",
    "        })\n",
    "\n",
    "    # Write individual user files and build summary\n",
    "    for username, user_data in users_by_name.items():\n",
    "        lab.write_json(f\"user-summaries/users/{username}.json\", user_data)\n",
    "        summary.append({\n",
    "            \"name\": username,\n",
    "            \"node_count\": len(user_data[\"nodes\"])\n",
    "        })\n",
    "        \n",
    "    # Write summary file\n",
    "    lab.write_json(\"user-summaries/summary.json\", summary)\n",
    "        \n",
    "    lab.log.info(f\"Wrote summary data for {len(users_by_name)} users\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
