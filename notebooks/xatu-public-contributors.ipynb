{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xatu Public Contributors Analysis\n",
    "\n",
    "This notebook fetches and analyzes public contributor data from Clickhouse and generates JSON files for the frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 12:16:35,391 - xatu-public-contributors - INFO - Good to go!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from lib import Lab\n",
    "\n",
    "# Initialize lab\n",
    "lab = Lab('xatu-public-contributors', '../config.yaml')\n",
    "lab.setup()\n",
    "lab.setup_pandaops_clickhouse()\n",
    "log = lab.log\n",
    "\n",
    "# Get notebook specific config\n",
    "notebook_config = lab.get_notebook_config()\n",
    "\n",
    "writer = lab.get_data_writer()\n",
    "\n",
    "pandaops_clickhouse_client = lab.get_pandaops_clickhouse_client()\n",
    "\n",
    "log.info(\"Good to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XatuPublicContributors(time_windows=[TimeWindow(file='last_30_days', step='1d', label='Last 30d', range='-30d'), TimeWindow(file='last_1_day', step='1h', label='Last 1d', range='-1d'), TimeWindow(file='last_90_days', step='3d', label='Last 90d', range='-90d')], data_dir='../data/xatu-public-contributors', networks=['mainnet', 'sepolia', 'holesky'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xatu_public_contributors_config = lab.get_notebook_config().as_xatu_public_contributors()\n",
    "xatu_public_contributors_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 12:39:47,849 - xatu-public-contributors - INFO - Fetching data for last_30_days, total timesteps: 30.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Connection.execute() got an unexpected keyword argument 'columnar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m total_timesteps \u001b[38;5;241m=\u001b[39m (end_date \u001b[38;5;241m-\u001b[39m start_date)\u001b[38;5;241m.\u001b[39mtotal_seconds() \u001b[38;5;241m/\u001b[39m step_seconds\n\u001b[1;32m     40\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, total timesteps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_timesteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m result \u001b[38;5;241m=\u001b[39m pandaops_clickhouse_client\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m     43\u001b[0m     query,\n\u001b[1;32m     44\u001b[0m     {\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: start_str, \n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: end_str,\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetworks\u001b[39m\u001b[38;5;124m\"\u001b[39m: xatu_public_contributors_config\u001b[38;5;241m.\u001b[39mnetworks,\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m: step_seconds\n\u001b[1;32m     49\u001b[0m     },\n\u001b[1;32m     50\u001b[0m     columnar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m countries \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(countries) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Connection.execute() got an unexpected keyword argument 'columnar'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "query = text(\"\"\"\n",
    "    WITH time_slots AS (\n",
    "        SELECT \n",
    "            toStartOfInterval(slot_start_date_time, INTERVAL :step_seconds second) as time_slot,\n",
    "            meta_client_geo_country as country,\n",
    "            meta_network_name,\n",
    "            count(distinct meta_client_name) AS total\n",
    "        FROM beacon_api_eth_v1_events_block FINAL\n",
    "        WHERE\n",
    "            slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "            AND meta_client_name NOT LIKE 'ethpandaops%'\n",
    "            AND meta_network_name IN (:networks)\n",
    "            AND meta_client_name != ''\n",
    "            AND meta_client_name IS NOT NULL\n",
    "        GROUP BY time_slot, country, meta_network_name\n",
    "    )\n",
    "    SELECT\n",
    "        toDate(time_slot) as time,\n",
    "        country,\n",
    "        meta_network_name,\n",
    "        total\n",
    "    FROM time_slots\n",
    "\"\"\")\n",
    "\n",
    "countries_by_window = {}\n",
    "\n",
    "for window in xatu_public_contributors_config.time_windows:\n",
    "    start_date, end_date = window.get_time_range(datetime.now(timezone.utc))\n",
    "    step_seconds = window.get_step_seconds()\n",
    "    \n",
    "    # Format dates without microseconds for Clickhouse\n",
    "    start_str = start_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_str = end_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    total_timesteps = (end_date - start_date).total_seconds() / step_seconds\n",
    "\n",
    "    log.info(f\"Fetching data for {window.file}, total timesteps: {total_timesteps}\")\n",
    "    \n",
    "    result = pandaops_clickhouse_client.execute(\n",
    "        query,\n",
    "        {\n",
    "            \"start_date\": start_str, \n",
    "            \"end_date\": end_str,\n",
    "            \"networks\": xatu_public_contributors_config.networks,\n",
    "            \"step_seconds\": step_seconds\n",
    "        }\n",
    "    )\n",
    "    countries = result.fetchall()\n",
    "\n",
    "    if len(countries) == 0:\n",
    "        log.warning(f\"No countries found for time window {window.file}\")\n",
    "        continue\n",
    "\n",
    "    countries_by_window[window.file] = countries\n",
    "    log.info(f\"Found {len(countries)} countries for time window {window.file}\")\n",
    "    \n",
    "    # Group by network and write separate files\n",
    "    for network in xatu_public_contributors_config.networks:\n",
    "        network_countries = [c for c in countries if c[2] == network]\n",
    "        if not network_countries:\n",
    "            continue\n",
    "        \n",
    "        # Group by timestamp\n",
    "        time_grouped = []\n",
    "        for c in network_countries:\n",
    "            timestamp = int(datetime.combine(c[0], datetime.min.time()).timestamp())\n",
    "            time_grouped.append({\n",
    "                \"time\": timestamp,\n",
    "                \"countries\": [{\n",
    "                    \"name\": c[1],\n",
    "                    \"value\": c[3]\n",
    "                }]\n",
    "            })\n",
    "            \n",
    "        # Merge entries with same timestamp\n",
    "        merged = {}\n",
    "        for entry in time_grouped:\n",
    "            if entry[\"time\"] not in merged:\n",
    "                merged[entry[\"time\"]] = entry\n",
    "            else:\n",
    "                merged[entry[\"time\"]][\"countries\"].extend(entry[\"countries\"])\n",
    "                \n",
    "        # Convert to list and write to file\n",
    "        final_data = list(merged.values())\n",
    "        \n",
    "        # Write to single file per time window and network\n",
    "        lab.write_json(f\"countries/{network}/{window.file}.json\", final_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
