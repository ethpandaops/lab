{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 15:37:44,383 - beacon-chain-overview - INFO - Good to go!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from lib import Lab\n",
    "\n",
    "# Initialize lab\n",
    "lab = Lab('beacon-chain-overview', '../config.yaml')\n",
    "lab.setup()\n",
    "lab.setup_pandaops_clickhouse()\n",
    "log = lab.log\n",
    "\n",
    "# Get notebook specific config\n",
    "notebook_config = lab.get_notebook_config()\n",
    "\n",
    "writer = lab.get_data_writer()\n",
    "\n",
    "pandaops_clickhouse_client = lab.get_pandaops_clickhouse_client()\n",
    "\n",
    "## Clear the data directory\n",
    "lab.delete_directory('')\n",
    "\n",
    "log.info(\"Good to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeaconChainOverview(networks=['mainnet'], data_dir='../data/beacon-chain-overview')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beacon_chain_overview_config = lab.get_notebook_config().as_beacon_chain_overview()\n",
    "beacon_chain_overview_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseException",
     "evalue": "Orig exception: Code: 47. DB::Exception: Missing columns: 'slot_start_date_time' while processing query: 'SELECT count() AS total_validators, countIf(status = 'active_ongoing') AS active_validators FROM canonical_beacon_validators FINAL WHERE (meta_network_name = 'mainnet') AND ((slot_start_date_time >= toDateTime('2025-02-04 05:37:49')) AND (slot_start_date_time <= toDateTime('2025-02-11 05:37:49')))', required columns: 'meta_network_name' 'slot_start_date_time' 'status', maybe you meant: 'meta_network_name', 'epoch_start_date_time' or 'status'. (UNKNOWN_IDENTIFIER) (version 24.2.3.70 (official build))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: start_str, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: end_str}\n\u001b[1;32m     80\u001b[0m finalized_result \u001b[38;5;241m=\u001b[39m pandaops_clickhouse_client\u001b[38;5;241m.\u001b[39mexecute(finalized_query, params)\u001b[38;5;241m.\u001b[39mfetchone()\n\u001b[0;32m---> 81\u001b[0m validator_result \u001b[38;5;241m=\u001b[39m pandaops_clickhouse_client\u001b[38;5;241m.\u001b[39mexecute(validator_query, params)\u001b[38;5;241m.\u001b[39mfetchone()\n\u001b[1;32m     82\u001b[0m slashing_result \u001b[38;5;241m=\u001b[39m pandaops_clickhouse_client\u001b[38;5;241m.\u001b[39mexecute(slashing_query, params)\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m     83\u001b[0m exits_result \u001b[38;5;241m=\u001b[39m pandaops_clickhouse_client\u001b[38;5;241m.\u001b[39mexecute(exits_query, params)\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1630\u001b[0m )\n\u001b[1;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1639\u001b[0m )\n\u001b[0;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1655\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m         ret,\n\u001b[1;32m   1660\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2356\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2354\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2355\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2356\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2358\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1974\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1979\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/base.py:488\u001b[0m, in \u001b[0;36mClickHouseDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 488\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/connector.py:133\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, operation, parameters, context)\u001b[0m\n\u001b[1;32m    130\u001b[0m raw_sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare(raw_sql, context)\n\u001b[1;32m    131\u001b[0m response_gen \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mexecute(raw_sql, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end_query()\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/connector.py:232\u001b[0m, in \u001b[0;36mCursor._process_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, response):\n\u001b[1;32m    230\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(response)\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(response, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response \u001b[38;5;241m=\u001b[39m response\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/transport.py:133\u001b[0m, in \u001b[0;36mRequestsTransport.execute\u001b[0;34m(self, query, params)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    Query is returning rows and these rows should be parsed or\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    there is nothing to return.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     lines \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39miter_lines()\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/transport.py:179\u001b[0m, in \u001b[0;36mRequestsTransport._send\u001b[0;34m(self, data, params, stream)\u001b[0m\n\u001b[1;32m    177\u001b[0m     orig \u001b[38;5;241m=\u001b[39m HTTPException(r\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    178\u001b[0m     orig\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus_code\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatabaseException(orig)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mDatabaseException\u001b[0m: Orig exception: Code: 47. DB::Exception: Missing columns: 'slot_start_date_time' while processing query: 'SELECT count() AS total_validators, countIf(status = 'active_ongoing') AS active_validators FROM canonical_beacon_validators FINAL WHERE (meta_network_name = 'mainnet') AND ((slot_start_date_time >= toDateTime('2025-02-04 05:37:49')) AND (slot_start_date_time <= toDateTime('2025-02-11 05:37:49')))', required columns: 'meta_network_name' 'slot_start_date_time' 'status', maybe you meant: 'meta_network_name', 'epoch_start_date_time' or 'status'. (UNKNOWN_IDENTIFIER) (version 24.2.3.70 (official build))\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# Set time window\n",
    "end_date = datetime.now(timezone.utc)\n",
    "start_date = end_date - timedelta(days=7)\n",
    "start_str = start_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "end_str = end_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Query finalized epoch and validator info\n",
    "finalized_query = text(\"\"\"\n",
    "    SELECT\n",
    "        max(epoch) as max_finalized_epoch,\n",
    "        max(epoch_start_date_time) as finalized_epoch_time\n",
    "    FROM canonical_beacon_block FINAL\n",
    "    WHERE \n",
    "        meta_network_name = 'mainnet'\n",
    "        AND slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "\"\"\")\n",
    "\n",
    "validator_query = text(\"\"\"\n",
    "    SELECT\n",
    "        count(*) as total_validators,\n",
    "        countIf(status = 'active_ongoing') as active_validators\n",
    "    FROM canonical_beacon_validators FINAL\n",
    "    WHERE \n",
    "        meta_network_name = 'mainnet'\n",
    "        AND epoch_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "\"\"\")\n",
    "\n",
    "# Get recent slashings\n",
    "slashing_query = text(\"\"\"\n",
    "    SELECT\n",
    "        'proposer' as type,\n",
    "        header_1_slot as slot,\n",
    "        proposer_index\n",
    "    FROM canonical_beacon_block_proposer_slashing FINAL\n",
    "    WHERE \n",
    "        meta_network_name = 'mainnet'\n",
    "        AND slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'attester' as type,\n",
    "        attestation_1_data_slot as slot,\n",
    "        arrayJoin(attestation_1_attesting_indices) as validator_index\n",
    "    FROM canonical_beacon_block_attester_slashing FINAL\n",
    "    WHERE \n",
    "        meta_network_name = 'mainnet'\n",
    "        AND slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "\"\"\")\n",
    "\n",
    "# Get recent voluntary exits\n",
    "exits_query = text(\"\"\"\n",
    "    SELECT\n",
    "        validator_index,\n",
    "        epoch\n",
    "    FROM canonical_beacon_block_voluntary_exit FINAL\n",
    "    WHERE \n",
    "        meta_network_name = 'mainnet'\n",
    "        AND slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "\"\"\")\n",
    "\n",
    "# Get last 3 epochs of blocks\n",
    "blocks_query = text(\"\"\"\n",
    "    SELECT\n",
    "        epoch,\n",
    "        slot,\n",
    "        count(*) as blocks_in_slot\n",
    "    FROM canonical_beacon_block FINAL\n",
    "    WHERE \n",
    "        meta_network_name = 'mainnet'\n",
    "        AND slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "    GROUP BY epoch, slot\n",
    "    ORDER BY slot DESC\n",
    "\"\"\")\n",
    "\n",
    "# Execute queries with time params\n",
    "params = {\"start_date\": start_str, \"end_date\": end_str}\n",
    "\n",
    "finalized_result = pandaops_clickhouse_client.execute(finalized_query, params).fetchone()\n",
    "validator_result = pandaops_clickhouse_client.execute(validator_query, params).fetchone()\n",
    "slashing_result = pandaops_clickhouse_client.execute(slashing_query, params).fetchall()\n",
    "exits_result = pandaops_clickhouse_client.execute(exits_query, params).fetchall()\n",
    "blocks_result = pandaops_clickhouse_client.execute(blocks_query, params).fetchall()\n",
    "\n",
    "# Format data\n",
    "overview_data = {\n",
    "    \"finalized_epoch\": finalized_result[0],\n",
    "    \"finalized_epoch_time\": int(finalized_result[1].timestamp()),\n",
    "    \"validators\": {\n",
    "        \"total\": validator_result[0],\n",
    "        \"active\": validator_result[1]\n",
    "    },\n",
    "    \"recent_slashings\": [\n",
    "        {\n",
    "            \"type\": s[0],\n",
    "            \"slot\": s[1],\n",
    "            \"validator_index\": s[2]\n",
    "        } for s in slashing_result\n",
    "    ],\n",
    "    \"recent_exits\": [\n",
    "        {\n",
    "            \"validator_index\": e[0],\n",
    "            \"epoch\": e[1]\n",
    "        } for e in exits_result\n",
    "    ],\n",
    "    \"recent_blocks\": [\n",
    "        {\n",
    "            \"epoch\": b[0],\n",
    "            \"slot\": b[1],\n",
    "            \"blocks\": b[2]\n",
    "        } for b in blocks_result\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Write overview data\n",
    "lab.write_json(\"overview.json\", overview_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 17:38:04,941 - beacon-chain-timings - INFO - Fetching block and blob data for last_30_days (2024-12-11 07:38:04 to 2025-01-10 07:38:04)\n",
      "2025-01-10 17:38:04,942 - beacon-chain-timings - INFO - Querying blob data...\n",
      "2025-01-10 17:38:09,475 - beacon-chain-timings - INFO - Found blob data for 503400 slots\n",
      "2025-01-10 17:38:09,476 - beacon-chain-timings - INFO - Querying MEV relay data...\n",
      "2025-01-10 17:38:11,216 - beacon-chain-timings - INFO - Found 264044 MEV relay slots\n",
      "2025-01-10 17:38:11,216 - beacon-chain-timings - INFO - Querying block arrival data...\n",
      "2025-01-10 17:38:11,217 - beacon-chain-timings - INFO - Querying block size data...\n",
      "2025-01-10 17:38:17,907 - beacon-chain-timings - INFO - Found arrival data for 621757 blocks\n",
      "2025-01-10 17:38:22,072 - beacon-chain-timings - INFO - Found size data for 619833 blocks\n",
      "2025-01-10 17:38:22,073 - beacon-chain-timings - INFO - Getting proposer entities...\n",
      "2025-01-10 17:38:31,121 - beacon-chain-timings - INFO - Merged data contains 619833 blocks\n",
      "2025-01-10 17:38:31,121 - beacon-chain-timings - INFO - Processing network mainnet...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'solo_stakers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 143\u001b[0m\n\u001b[1;32m    141\u001b[0m network_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_mev\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m network_df\u001b[38;5;241m.\u001b[39mslot\u001b[38;5;241m.\u001b[39misin(mev_slots)\n\u001b[1;32m    142\u001b[0m network_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(network_df, proposer_entities, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproposer_index\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 143\u001b[0m network_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_solo\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m network_df\u001b[38;5;241m.\u001b[39mentity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolo_stakers\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Bucket sizes into 32KB chunks and get average arrival time per bucket\u001b[39;00m\n\u001b[1;32m    146\u001b[0m network_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize_bucket\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (network_df\u001b[38;5;241m.\u001b[39mtotal_size \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m))\u001b[38;5;241m.\u001b[39mround() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'solo_stakers'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fetch block sizes, blob data and build CDF for each time window\n",
    "for window in beacon_chain_timings_config.time_windows:\n",
    "    start_date, end_date = window.get_time_range(datetime.now(timezone.utc))\n",
    "    start_str = start_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_str = end_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    log.info(f\"Fetching block and blob data for {window.file} ({start_str} to {end_str})\")\n",
    "\n",
    "    # Get blob data\n",
    "    log.info(\"Querying blob data...\")\n",
    "    blob_query = text(\"\"\"\n",
    "        SELECT\n",
    "            slot,\n",
    "            COUNT(*) * 131072 as total_blob_bytes -- 128KB per blob\n",
    "        FROM canonical_beacon_blob_sidecar FINAL\n",
    "        WHERE\n",
    "            slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "            AND meta_network_name IN (:networks)\n",
    "        GROUP BY slot\n",
    "    \"\"\")\n",
    "\n",
    "    blob_result = pandaops_clickhouse_client.execute(\n",
    "        blob_query,\n",
    "        {\n",
    "            \"start_date\": start_str,\n",
    "            \"end_date\": end_str,\n",
    "            \"networks\": beacon_chain_timings_config.networks\n",
    "        }\n",
    "    )\n",
    "    blob_data = {r[0]: r[1] for r in blob_result.fetchall()}\n",
    "    log.info(f\"Found blob data for {len(blob_data)} slots\")\n",
    "\n",
    "    # Get MEV relay data\n",
    "    log.info(\"Querying MEV relay data...\")\n",
    "    mev_query = text(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            slot\n",
    "        FROM mev_relay_proposer_payload_delivered FINAL\n",
    "        WHERE\n",
    "            slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "            AND meta_network_name IN (:networks)\n",
    "    \"\"\")\n",
    "    \n",
    "    mev_result = pandaops_clickhouse_client.execute(\n",
    "        mev_query,\n",
    "        {\n",
    "            \"start_date\": start_str,\n",
    "            \"end_date\": end_str,\n",
    "            \"networks\": beacon_chain_timings_config.networks\n",
    "        }\n",
    "    )\n",
    "    mev_slots = set(r[0] for r in mev_result.fetchall())\n",
    "    log.info(f\"Found {len(mev_slots)} MEV relay slots\")\n",
    "\n",
    "    # Get block arrival data\n",
    "    log.info(\"Querying block arrival data...\")\n",
    "    block_arrival_query = text(\"\"\"\n",
    "        SELECT \n",
    "            slot,\n",
    "            meta_network_name,\n",
    "            min(propagation_slot_start_diff) as arrival_time\n",
    "        FROM beacon_api_eth_v1_events_block FINAL\n",
    "        WHERE\n",
    "            slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "            AND meta_network_name IN (:networks)\n",
    "        GROUP BY slot, meta_network_name\n",
    "    \"\"\")\n",
    "\n",
    "    # Get block size data\n",
    "    log.info(\"Querying block size data...\")\n",
    "    block_size_query = text(\"\"\"\n",
    "        SELECT \n",
    "            slot,\n",
    "            meta_network_name,\n",
    "            proposer_index,\n",
    "            block_total_bytes_compressed\n",
    "        FROM canonical_beacon_block FINAL\n",
    "        WHERE\n",
    "            slot_start_date_time BETWEEN toDateTime(:start_date) AND toDateTime(:end_date)\n",
    "            AND meta_network_name IN (:networks)\n",
    "    \"\"\")\n",
    "\n",
    "    params = {\n",
    "        \"start_date\": start_str,\n",
    "        \"end_date\": end_str,\n",
    "        \"networks\": beacon_chain_timings_config.networks\n",
    "    }\n",
    "\n",
    "    # Execute queries and convert to dataframes\n",
    "    arrival_df = pd.DataFrame(\n",
    "        pandaops_clickhouse_client.execute(block_arrival_query, params).fetchall(),\n",
    "        columns=['slot', 'meta_network_name', 'arrival_time']\n",
    "    )\n",
    "    log.info(f\"Found arrival data for {len(arrival_df)} blocks\")\n",
    "    \n",
    "    size_df = pd.DataFrame(\n",
    "        pandaops_clickhouse_client.execute(block_size_query, params).fetchall(),\n",
    "        columns=['slot', 'meta_network_name', 'proposer_index', 'block_size']\n",
    "    )\n",
    "    log.info(f\"Found size data for {len(size_df)} blocks\")\n",
    "\n",
    "    # Get proposer entities\n",
    "    log.info(\"Getting proposer entities...\")\n",
    "    proposer_query = text(\"\"\"\n",
    "        SELECT \n",
    "            `index` as proposer_index,\n",
    "            entity\n",
    "        FROM ethseer_validator_entity\n",
    "        WHERE \n",
    "            meta_network_name IN (:networks)\n",
    "    \"\"\")\n",
    "    proposer_entities = pd.DataFrame(\n",
    "        pandaops_clickhouse_client.execute(proposer_query, params).fetchall(),\n",
    "        columns=['proposer_index', 'entity']\n",
    "    )\n",
    "\n",
    "    # Merge dataframes and only keep slots that exist in size_df (canonical blocks)\n",
    "    block_data = pd.merge(\n",
    "        arrival_df, \n",
    "        size_df,\n",
    "        on=['slot', 'meta_network_name'],\n",
    "        how='right'\n",
    "    ).dropna()\n",
    "    log.info(f\"Merged data contains {len(block_data)} blocks\")\n",
    "\n",
    "    # Process each network\n",
    "    for network in beacon_chain_timings_config.networks:\n",
    "        log.info(f\"Processing network {network}...\")\n",
    "        network_df = block_data[block_data.meta_network_name == network].copy()\n",
    "        if network_df.empty:\n",
    "            log.warning(f\"No data found for network {network}\")\n",
    "            continue\n",
    "            \n",
    "        # Add blob sizes, MEV flag and entity info\n",
    "        network_df['total_size'] = network_df.apply(\n",
    "            lambda row: max(row.block_size + blob_data.get(row.slot, 0), 1),  # Ensure minimum size of 1 byte\n",
    "            axis=1\n",
    "        )\n",
    "        network_df['is_mev'] = network_df.slot.isin(mev_slots)\n",
    "        network_df = pd.merge(network_df, proposer_entities, on='proposer_index', how='left')\n",
    "        network_df['is_solo'] = network_df.entity == 'solo_stakers'\n",
    "\n",
    "        # Bucket sizes into 32KB chunks and get average arrival time per bucket\n",
    "        network_df['size_bucket'] = (network_df.total_size / (32 * 1024)).round() * 32\n",
    "        network_df['size_bucket'] = network_df['size_bucket'].apply(lambda x: max(x, 32))  # Minimum bucket of 32KB\n",
    "        \n",
    "        # Calculate averages for all blocks, MEV blocks, non-MEV blocks, and solo staker blocks\n",
    "        avg_all = network_df.groupby('size_bucket')['arrival_time'].mean().round().reset_index()\n",
    "        avg_mev = network_df[network_df.is_mev].groupby('size_bucket')['arrival_time'].mean().round().reset_index()\n",
    "        avg_non_mev = network_df[~network_df.is_mev].groupby('size_bucket')['arrival_time'].mean().round().reset_index()\n",
    "        avg_solo_mev = network_df[network_df.is_solo & network_df.is_mev].groupby('size_bucket')['arrival_time'].mean().round().reset_index()\n",
    "        avg_solo_non_mev = network_df[network_df.is_solo & ~network_df.is_mev].groupby('size_bucket')['arrival_time'].mean().round().reset_index()\n",
    "\n",
    "        # Write data\n",
    "        formatted_data = {\n",
    "            \"sizes_kb\": avg_all.size_bucket.tolist(),\n",
    "            \"arrival_times_ms\": {\n",
    "                \"all\": avg_all.arrival_time.tolist(),\n",
    "                \"mev\": avg_mev.arrival_time.tolist() if not avg_mev.empty else [],\n",
    "                \"non_mev\": avg_non_mev.arrival_time.tolist() if not avg_non_mev.empty else [],\n",
    "                \"solo_mev\": avg_solo_mev.arrival_time.tolist() if not avg_solo_mev.empty else [],\n",
    "                \"solo_non_mev\": avg_solo_non_mev.arrival_time.tolist() if not avg_solo_non_mev.empty else []\n",
    "            }\n",
    "        }\n",
    "\n",
    "        output_path = f\"size_cdf/{network}/{window.file}.json\"\n",
    "        log.info(f\"Writing data to {output_path}\")\n",
    "        lab.write_json(output_path, formatted_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
